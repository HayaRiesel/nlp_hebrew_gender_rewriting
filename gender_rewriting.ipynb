{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas_ods_reader import read_ods\n",
    "\n",
    "df = read_ods('data/inflections_urldecoded.ods')\n",
    "df.replace(to_replace=[None], value='', inplace=True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_inflection(word, basePos, root,baseGender,tense,baseNumber,basePerson,binyan,PGN, type, baseLexiconPointer,value):\n",
    "    if baseGender == 'feminine':\n",
    "        baseGender = 'masculine'\n",
    "    elif baseGender == 'masculine':\n",
    "        baseGender = 'feminine'\n",
    "\n",
    "    if basePos == 'numeral':\n",
    "        change_gender_word = df.loc[(df['basePos'] == basePos) &\n",
    "           (df['root'] == root) &\n",
    "           (df['baseGender'] == baseGender) &\n",
    "           (df['tense'] == tense) &\n",
    "           (df['basePerson'] == basePerson) &\n",
    "           (df['binyan'] == binyan) &\n",
    "           (df['type'] == type) &\n",
    "           (df['PGN'] == PGN) &\n",
    "           (df['value'] == value)\n",
    "        ]\n",
    "    else:\n",
    "        change_gender_word = df.loc[(df['basePos'] == basePos) &\n",
    "           (df['root'] == root) &\n",
    "           (df['baseGender'] == baseGender) &\n",
    "           (df['tense'] == tense) &\n",
    "           (df['baseNumber'] == baseNumber) &\n",
    "           (df['basePerson'] == basePerson) &\n",
    "           (df['binyan'] == binyan) &\n",
    "           (df['type'] == type) &\n",
    "           (df['PGN'] == PGN) &\n",
    "           (df['baseLexiconPointer'] == baseLexiconPointer)\n",
    "        ]\n",
    "    if len(change_gender_word) == 0:\n",
    "        return None\n",
    "    return change_gender_word['surface'].values[0]\n",
    "    # another_inflection = df.loc[df['surface'] == word]\n",
    "    # print(another_inflection)\n",
    "\n",
    "\n",
    "\n",
    "gender_dict = {\n",
    "    'feminine': 'feminine',\n",
    "    'masculine': 'masculine',\n",
    "    'F': 'feminine',\n",
    "    'M': 'masculine'\n",
    "}\n",
    "tense_dict = {\n",
    "    'FUTURE': 'future',\n",
    "    'IMPERATIVE':'imperative',\n",
    "    '-1': 'unspecified',\n",
    "    '': '',\n",
    "    'beinoni': 'beinoni',\n",
    "    'BEINONI': 'beinoni',\n",
    "    'PAST': 'past'\n",
    "}\n",
    "def get_inflection_specific_word(word, type, gender, tense):\n",
    "    gender = gender_dict[gender]\n",
    "    tense = tense_dict[str(tense)]\n",
    "    if tense == '':\n",
    "                another_inflection = df.loc[(df['surface'] == word) &\n",
    "                                    ((df['type'] == type) | (df['basePos'] == type))\n",
    "                                    & (df['baseGender'] == gender)\n",
    "        ]\n",
    "    else:\n",
    "        another_inflection = df.loc[(df['surface'] == word) &\n",
    "                                    ((df['type'] == type) | (df['basePos'] == type))\n",
    "                                    & (df['baseGender'] == gender)\n",
    "                                    & (df['tense'] == tense)\n",
    "        ]\n",
    "    if len(another_inflection) == 0:\n",
    "        another_inflection = df.loc[(df['surface'] == word) &\n",
    "                                    ((df['type'] == type) | (df['basePos'] == type))\n",
    "                                    & (df['baseGender'] == gender)\n",
    "                                    & (df['tense'] == 'beinoni')\n",
    "        ]\n",
    "        if len(another_inflection) == 0:\n",
    "            return None\n",
    "    # select_word = another_inflection.iloc[0]\n",
    "    for index, select_word in another_inflection.iterrows():\n",
    "        basePos = select_word['basePos']\n",
    "        root = select_word['root']\n",
    "        baseGender = select_word['baseGender']\n",
    "        tense = select_word['tense']\n",
    "        baseNumber = select_word['baseNumber']\n",
    "        basePerson = select_word['basePerson']\n",
    "        binyan = select_word['binyan']\n",
    "        PGN = select_word['PGN']\n",
    "        type = select_word['type']\n",
    "        baseLexiconPointer = select_word['baseLexiconPointer']\n",
    "        value = select_word['value']\n",
    "        change_word = get_inflection(select_word, basePos, root, baseGender, tense, baseNumber, basePerson, binyan, PGN, type,baseLexiconPointer,value)\n",
    "        if change_word != None:\n",
    "            break\n",
    "    else:\n",
    "        change_word = None\n",
    "\n",
    "    return change_word\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "yap_token = \"ca1e42cb5ee83d4e0224df9e335bcd9e\"\n",
    "url = f'https://www.langndata.com/api/heb_parser?token={yap_token}'\n",
    "\n",
    "#gen,num_s_p,per,tense\n",
    "def get_word_info(json_obj):\n",
    "    md_lattice = json_obj[\"md_lattice\"]\n",
    "    # ma_lattice = json_obj[\"ma_lattice\"]\n",
    "    res_df = pd.json_normalize([md_lattice[i] for i in md_lattice.keys()])\n",
    "    # res_df_ma_lattice = pd.json_normalize([ma_lattice[i] for i in ma_lattice.keys()])\n",
    "\n",
    "    res_df = res_df[['word', 'lemma', 'gen', 'num_s_p', 'per', 'tense','pos']]\n",
    "    # res_df_ma_lattice = res_df_ma_lattice[['word', 'lemma', 'gen', 'num_s_p', 'per', 'tense']]\n",
    "\n",
    "    return res_df\n",
    "\n",
    "#gen,num_s_p,per,tense\n",
    "def get_word_info_hebrew_nlp(text):\n",
    "    request = {\n",
    "        'token': 'TW5M2ZoDwIahTGJ',\n",
    "        'readable': False,\n",
    "        'paragraph': text\n",
    "    }\n",
    "    result = requests.post('https://hebrew-nlp.co.il/service/Morphology/Analyze', json=request).json()[0]\n",
    "    result = [item[0] for item in result]\n",
    "    res_df = pd.json_normalize([result[i] for i in range(len(result))])\n",
    "    res_df = res_df[['baseWordMenukad', 'gender', 'plural', 'person', 'tense','partOfSpeech']]\n",
    "    # res_df['baseWordMenukad'] = res_df['baseWordMenukad'][:-1] + res_df['baseWordMenukad'][-1].upper()\n",
    "    return res_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "#subject relate to the word\n",
    "def is_relate_to_subject(dep_tree_df, word_ind, subject_ind):\n",
    "    subject_details = dep_tree_df.iloc[subject_ind]\n",
    "    return subject_details['dependency_arc'] == int(word_ind)\n",
    "\n",
    "# word relate to PRP - no need?\n",
    "# def is_relate_to_subject_PRP(dep_tree_df, word_ind, subject_ind,df_word_info):\n",
    "#     word_detail = dep_tree_df.iloc[word_ind]\n",
    "#     relate_word_dep_tree = dep_tree_df.loc[word_detail['dependency_arc'] == dep_tree_df['num']].iloc[0]\n",
    "#     related_word_ind = relate_word_dep_tree['num']\n",
    "#     relate_word_info = df_word_info.iloc[int(related_word_ind) - 1]\n",
    "#     if relate_word_dep_tree['pos'] == 'PRP' and relate_word_info['per'] == 2:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "#PRP relate to word\n",
    "def is_relate_to_subject_PRP(dep_tree_df, word_ind, subject_ind,df_word_info):\n",
    "    word_detail = dep_tree_df.iloc[word_ind]\n",
    "    #get all PRP with per 2\n",
    "    all_PRP = df_word_info.loc[((df_word_info['pos'] == 'PRP') & (df_word_info['per'] == '2'))]\n",
    "    word_num = word_ind + 1\n",
    "    for index in all_PRP.index.values.tolist():\n",
    "        if int(dep_tree_df.iloc[index]['dependency_arc']) == word_num:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#word relate to AT\n",
    "# def is_relate_to_subject_AT(dep_tree_df, word_ind, subject_ind,df_word_info):\n",
    "#     word_detail = dep_tree_df.iloc[word_ind]\n",
    "#     #get all PRP with per 2\n",
    "#     all_AT = df_word_info.loc[df_word_info['pos'] == 'AT']\n",
    "#     word_num = word_ind + 1\n",
    "#     for index in all_AT.index.values.tolist():\n",
    "#         if int(dep_tree_df.iloc[word_ind]['dependency_arc']) == dep_tree_df.iloc[index]['num']:\n",
    "#             return True\n",
    "#     return False\n",
    "\n",
    "#PRP relate to word\n",
    "def is_relate_to_subject_PRP_not_of_per_2(dep_tree_df, word_ind, subject_ind,df_word_info):\n",
    "    word_detail = dep_tree_df.iloc[word_ind]\n",
    "    #get all PRP with per 2\n",
    "    all_PRP = df_word_info.loc[(df_word_info['pos'] == 'PRP') & (df_word_info['per'] != '2')]\n",
    "    word_num = word_ind + 1\n",
    "    for index in all_PRP.index.values.tolist():\n",
    "        if int(dep_tree_df.iloc[index]['dependency_arc']) == word_num:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "#word relate to root and dont have any PRP from per 1/3 relate to it\n",
    "def is_relate_to_subject_2(dep_tree_df, word_ind,df_word_info):\n",
    "    word_detail = dep_tree_df.iloc[word_ind]\n",
    "    subject_num = dep_tree_df.loc[dep_tree_df['dependency_part'] == 'ROOT'].iloc[0]['num']\n",
    "\n",
    "    all_PRP = df_word_info.loc[(df_word_info['pos'] == 'PRP') & (df_word_info['per'] != '2')]\n",
    "    word_num = word_ind + 1\n",
    "    for index in all_PRP.index.values.tolist():\n",
    "        if int(dep_tree_df.iloc[index]['dependency_arc']) == word_num:\n",
    "            return False\n",
    "\n",
    "    return word_detail['dependency_arc'] == subject_num\n",
    "\n",
    "\n",
    "def is_relate_to_subject_bot_nn(dep_tree_df, word, wordDetail,word_ind,df_word_info):\n",
    "    subject_ind = dep_tree_df.index[dep_tree_df['dependency_part'] == 'ROOT'].tolist()[0]\n",
    "    dependency_arc = int(dep_tree_df.iloc[word_ind]['dependency_arc'])\n",
    "    head_of_nn_dep_arc_info = df_word_info.iloc[dependency_arc - 1]\n",
    "    if head_of_nn_dep_arc_info['pos'] == 'VB':\n",
    "        return False\n",
    "    if is_relate_to_subject_2(dep_tree_df, word_ind, df_word_info) or \\\n",
    "            is_relate_to_subject(dep_tree_df, word_ind, subject_ind)  or is_relate_to_subject_PRP(dep_tree_df, word_ind, subject_ind,df_word_info) or (subject_ind == word_ind and not is_relate_to_subject_PRP_of_per_1(dep_tree_df, word_ind, subject_ind,df_word_info)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def is_relate_to_subject_bot_jj(dep_tree_df, word, wordDetail,word_ind,df_word_info):\n",
    "    subject_ind = dep_tree_df.index[dep_tree_df['dependency_part'] == 'ROOT'].tolist()[0]\n",
    "    if is_relate_to_subject_2(dep_tree_df, word_ind, df_word_info) or \\\n",
    "            is_relate_to_subject(dep_tree_df, word_ind, subject_ind)  or is_relate_to_subject_PRP(dep_tree_df, word_ind, subject_ind,df_word_info) or (subject_ind == word_ind and not is_relate_to_subject_PRP_not_of_per_2(dep_tree_df, word_ind, subject_ind,df_word_info)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_relate_to_subject_bot(dep_tree_df, word, wordDetail,wodIndex,df_word_info):\n",
    "    #wordDetail['per'] == 'A or\n",
    "    if wordDetail['per'] == '2':\n",
    "        return True\n",
    "    if wordDetail['per'] == 'A':\n",
    "        return is_relate_to_subject_bot_jj(dep_tree_df, word, wordDetail,wodIndex,df_word_info)\n",
    "\n",
    "        # if is_relate_to_subject_2(dep_tree_df, word, subject) or is_relate_to_subject(dep_tree_df, word, subject) or subject == wodIndex:\n",
    "        #     return True\n",
    "        # else:\n",
    "        #     return False\n",
    "    return False\n",
    "    # return word_detail['dependency_arc'] == subject_num\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_req_from_yap(text):\n",
    "    text = text.replace(r'\"', r'\\\"')\n",
    "    _json = '{\"data\":\"' + text.strip() + '\"}'\n",
    "    sleep(3)\n",
    "    r = requests.post(url, data=_json.encode('utf-8'), headers={'Content-type': 'application/json; charset=utf-8'})\n",
    "    json_obj = r.json()\n",
    "    return json_obj\n",
    "\n",
    "def get_dep_tree(json_obj):\n",
    "    dep_tree = json_obj[\"dep_tree\"]\n",
    "    res_df = pd.json_normalize([dep_tree[i] for i in dep_tree.keys()])\n",
    "    return res_df\n",
    "\n",
    "\n",
    "personal_pronoun_dict = {\n",
    "    'אתה': 'את',\n",
    "    'את':'אתה',\n",
    "    'אתם':'אתן',\n",
    "    'אתן':'אתם',\n",
    "    'כן' : 'כם',\n",
    "    'כם' : 'כן',\n",
    "    'תן' : 'תם',\n",
    "    'תם': 'תן',\n",
    "    # 'הם':'הן',\n",
    "    # 'הן':'הם',\n",
    "    # 'הוא':'היא',\n",
    "    # 'היא':'הוא',\n",
    "}\n",
    "\n",
    "def is_PRP(word_info):\n",
    "    pos = word_info['pos']\n",
    "    if 'PRP' in pos or 'PRN' in pos:\n",
    "        return True\n",
    "    # elif pos == 'AT':\n",
    "    #     return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_untokenize(text, textArr, text_arr_is_change, df_word_info):\n",
    "    text_split_native = text.split(' ')\n",
    "    good_textArr = []\n",
    "    current_word = \"\"\n",
    "    for i, word in enumerate(textArr):\n",
    "        word_info = df_word_info.iloc[i]\n",
    "        if current_word != '' and word_info['pos'] == 'DEF':\n",
    "            continue\n",
    "        current_word += word\n",
    "        if word_info['pos'] in ['COM','TO','WDT','WP','PREPOSITION','DEF','REL','CONJ','TEMP'] \\\n",
    "                and not text_arr_is_change[i] \\\n",
    "                and (word_info['gen'] == -1 or word_info['num_s_p'] == -1 or word_info['per'] == -1 or word_info['tense'] == -1)\\\n",
    "                and len(word) < 3: #and word not in text_split_native\n",
    "            continue\n",
    "        else:\n",
    "            good_textArr.append(current_word)\n",
    "            current_word = \"\"\n",
    "    good_textArr[-1] += current_word\n",
    "    return good_textArr\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def change_sentence_gender(text,show_print=False):\n",
    "    text_by_sentence = text.split('\\n\\n')\n",
    "    json_obj = get_req_from_yap(text_by_sentence[0])\n",
    "    df_word_info = get_word_info(json_obj)\n",
    "    dep_tree = get_dep_tree(json_obj)\n",
    "    word_info_2 = get_word_info_hebrew_nlp(text)\n",
    "    textArr = df_word_info['word'].tolist()\n",
    "    text_arr_is_change = [False] * len(textArr)\n",
    "    for i, token in enumerate(df_word_info['word']):\n",
    "        # ret = is_relate_to_subject_2(dep_tree,token,'נעם')\n",
    "        # ret = is_relate_to_subject(dep_tree,token,'אליך')\n",
    "        # try:\n",
    "        # word_info = df_word_info.loc[df_word_info['word'] == token].iloc[0]\n",
    "        word_info = df_word_info.iloc[i]\n",
    "        is_jj = (word_info['pos'] == 'JJ')\n",
    "        is_verb = (word_info['pos'] in ['VB','BD','BG','BN','BP','BZ',''])\n",
    "        is_modal = (word_info['pos'] == 'MD')\n",
    "        is_num = (word_info['pos'] == 'CD')\n",
    "        is_noun = (word_info['pos'] == 'NN')\n",
    "        word_gender = word_info['gen']\n",
    "        # except:\n",
    "        #     continue\n",
    "        if is_noun:\n",
    "            ret = is_relate_to_subject_bot_nn(dep_tree, token, word_info,i,df_word_info)\n",
    "        elif is_jj or is_num:\n",
    "            ret = is_relate_to_subject_bot_jj(dep_tree, token, word_info,i,df_word_info)\n",
    "        elif is_verb or is_modal:\n",
    "            # if word_info['pos'] == 'BN':\n",
    "            #     ret = is_relate_to_subject_bot_jj(dep_tree, token, word_info,i,df_word_info)\n",
    "            # else:\n",
    "            ret = is_relate_to_subject_bot(dep_tree, token, word_info,i,df_word_info)\n",
    "        elif is_PRP(word_info):\n",
    "            ret = False\n",
    "            if token in personal_pronoun_dict:\n",
    "                new_word = personal_pronoun_dict[token]\n",
    "            else:\n",
    "                new_word = token\n",
    "            # dep_tree[dep_tree['word'] == token] = new_word\n",
    "            textArr[i] = new_word\n",
    "            text_arr_is_change[i] = True\n",
    "        else:\n",
    "            ret = False\n",
    "        if show_print:\n",
    "            print(token, ' : ', ret)\n",
    "        if ret:\n",
    "            # get_inflection_specific_word('הולכת',type='verb', gender='F', tense='beinoni')\n",
    "            if is_jj:\n",
    "                new_word = get_inflection_specific_word(token, type='adjective', gender=word_gender, tense='')\n",
    "            elif is_noun:\n",
    "                new_word = get_inflection_specific_word(token, type='noun', gender=word_gender, tense='')\n",
    "            elif is_num:\n",
    "                new_word = get_inflection_specific_word(token, type='numeral', gender=word_gender, tense='')\n",
    "            elif is_verb:\n",
    "                if word_info['pos'] == 'BN':\n",
    "                    new_word = get_inflection_specific_word(token, type='verb', gender=word_gender,\n",
    "                    tense='beinoni'\n",
    "                    )\n",
    "                new_word = get_inflection_specific_word(token, type='verb', gender=word_gender,\n",
    "                tense=word_info['tense']\n",
    "                )\n",
    "            elif is_modal:\n",
    "                new_word = get_inflection_specific_word(token, type='modal', gender=word_gender,\n",
    "                tense = word_info['tense']\n",
    "                # tense='unspecified'\n",
    "                )\n",
    "\n",
    "            # dep_tree[dep_tree['word'] == token] = new_word\n",
    "            textArr[i] = new_word\n",
    "            text_arr_is_change[i] = True\n",
    "\n",
    "\n",
    "    textArr = [word if word != None else \"None\" for word in textArr]\n",
    "\n",
    "    good_textArr = get_untokenize(text, textArr, text_arr_is_change, df_word_info)\n",
    "\n",
    "\n",
    "    new_sentence = \" \".join(good_textArr)\n",
    "    # print(dep_tree['word'])\n",
    "    return new_sentence\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin text: אתם חמישה עובדים\n",
      "text after gender rewriting: אתן חמש עובדות\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'אתם חמישה עובדים'\n",
    "print(f'origin text: {text}')\n",
    "print(f'text after gender rewriting: {change_sentence_gender(text)}')\n",
    "print('\\n\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}